{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from preprocessing import preprocess\n",
    "from spell_checker import SpellChecker\n",
    "from utils.amharic_tokenizer import AmharicSegmenter\n",
    "from utils.file_reader import read_file, read_lines\n",
    "from nltk import ngrams\n",
    "import time, pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_path = '../data/amharic_dictionary.txt'\n",
    "corpus_path = '../data/amharic_corpus.txt'\n",
    "tokenizer = AmharicSegmenter()\n",
    "spell_checker = SpellChecker(dictionary_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(text):\n",
    "    result = {\n",
    "        \"text\": text,\n",
    "        \"errors\": {}\n",
    "    }\n",
    "    text = preprocess(text)\n",
    "    print(text)\n",
    "    sentences = tokenizer.tokenize_sentence(text)\n",
    "    for sentence in sentences:\n",
    "        words = tokenizer.tokenize(sentence)\n",
    "        i = 0\n",
    "        for word in words:\n",
    "            if not spell_checker.check_spelling(word):\n",
    "                suggestions = spell_checker.suggest_corrections(word)\n",
    "                result[\"errors\"][word] = {\n",
    "                    'sentence': sentence,\n",
    "                    'tokenized': words,\n",
    "                    'suggestions': suggestions,\n",
    "                    'index': i}\n",
    "            i += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "import pickle\n",
    "\n",
    "class NgramModel:\n",
    "    def __init__(self, corpus: str, ngram_size=2):\n",
    "        self.corpus = corpus\n",
    "        self.tokenizer = AmharicSegmenter()\n",
    "        self.preprocess()\n",
    "        self.ngram_size = ngram_size\n",
    "        self.ngram_counts = defaultdict(int)\n",
    "    \n",
    "    def preprocess(self):\n",
    "        self.corpus = preprocess(self.corpus)\n",
    "        self.corpus = self.tokenizer.tokenize_sentence(self.corpus)\n",
    "        \n",
    "    def train(self):\n",
    "        for sentence in self.corpus:\n",
    "            words = self.tokenizer.tokenize(sentence)\n",
    "            for ngram in ngrams(words, self.ngram_size):\n",
    "                self.ngram_counts[ngram] += 1\n",
    "    \n",
    "    def get_ngram_count(self, ngram):\n",
    "        return self.ngram_counts[ngram]\n",
    "    \n",
    "    def get_ngram_probability(self, ngram):\n",
    "        ngram_count = self.get_ngram_count(ngram)\n",
    "        total_count = sum(self.ngram_counts.values())\n",
    "        return ngram_count / total_count\n",
    "\n",
    "    def save(self, path):\n",
    "        if not path.endswith('.pkl'):\n",
    "            path += '.pkl'\n",
    "        # check: if path does not exist create one\n",
    "        if not os.path.exists(os.path.dirname(path)):\n",
    "            os.makedirs(os.path.dirname(path))\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "    \n",
    "    def get_ngram_probability_with_smoothing(self, ngram):\n",
    "        \"\"\"\n",
    "        ngram: (a, b, c) = (before, word, after)\n",
    "        \"\"\" \n",
    "        ngram_count = self.get_ngram_count(ngram)\n",
    "        total_count = sum(self.ngram_counts.values())\n",
    "        return (ngram_count + 1) / (total_count + len(self.ngram_counts))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_reader import read_file\n",
    "corpus = read_file(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NgramModel(corpus, ngram_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/bigram_model_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_suggestions(dictionary_result):\n",
    "    result = {}\n",
    "    \n",
    "    for error, suggestion in dictionary_result[\"errors\"].items():\n",
    "        wrong_word = error\n",
    "        sentence = suggestion[\"sentence\"]\n",
    "        index = suggestion[\"index\"]\n",
    "        words = suggestion[\"tokenized\"]\n",
    "        suggestions = suggestion[\"suggestions\"]\n",
    "        \n",
    "        ngram = []\n",
    "        if len(words) == index-1 and len(words) > 1:\n",
    "            # the word is at the end of the sentence\n",
    "            before_word = words[index-1]\n",
    "            suggestions = sorted(suggestions, key=lambda x: model.get_ngram_probability((before_word,) + (x,)), reverse=True)\n",
    "        elif index == 0 and len(words) > 1:\n",
    "            # the word is at the beginning of the sentence\n",
    "            after_word = words[index+1]\n",
    "            suggestions = sorted(suggestions, key=lambda x: model.get_ngram_probability((x,) + (after_word,)), reverse=True)\n",
    "        elif len(words) == 1:\n",
    "            pass\n",
    "        else:\n",
    "            before_word = words[index-1] # we will use this to rank the suggestions\n",
    "            # after_word = words[index+1]\n",
    "            suggestions = sorted(suggestions, key=lambda x: model.get_ngram_probability((before_word,) + (x,)), reverse=True)\n",
    "            \n",
    "        \n",
    "        word_result = {\n",
    "            'sentence': sentence,\n",
    "            'suggestions': suggestions,\n",
    "        }\n",
    "        \n",
    "        result[wrong_word] = word_result\n",
    "    \n",
    "    return result\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "የቤት ውስጥ ስራ የሴቶች ስራ ብቻ ሳይቻሆን የሁሉም ሰው ሊሆን ይችላን።\n"
     ]
    }
   ],
   "source": [
    "sample_amharic_text = \"የቤት ውስጥ ስራ \\\"የሴቶች ስራ\\\" ብቻ ሳይቻሆን የሁሉም ሰው ሊሆን ይችላን።\"\n",
    "result = check(sample_amharic_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ሳይቻሆን': {'sentence': 'የቤት ውስጥ ስራ የሴቶች ስራ ብቻ ሳይቻሆን የሁሉም ሰው ሊሆን ይችላን።',\n",
       "  'suggestions': ['ሳይሆን', 'ሳይቻሆን']},\n",
       " 'ይችላን': {'sentence': 'የቤት ውስጥ ስራ የሴቶች ስራ ብቻ ሳይቻሆን የሁሉም ሰው ሊሆን ይችላን።',\n",
       "  'suggestions': ['ይችላል', 'ይችላሉ', 'ይችላን']}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_suggestions(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.566887202941682e-05"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_ngram_probability(('ሊሆን','ይችላል'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
